{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "today = time.strftime(\"%Y%m%d\", time.localtime())\n",
    "\n",
    "def cate_crawler(cate_key, cate_value):\n",
    "    cate_url = \"https://www.giftu.com.tw/ws_GetProdItemList.asmx/ShowClassSub\"\n",
    "    form_data = {'ClassSubId': cate_key}\n",
    "    r = requests.post(cate_url, data = form_data)\n",
    "    \n",
    "\n",
    "    prod_DOMAIN = \"http://www.giftu.com.tw/Product.aspx?\"\n",
    "    prod_urls = [prod_DOMAIN + x.replace(\"amp;\",\"\") for x in re.findall('ProdId=\\d+&amp;ProdItemId=\\d+', r.text)]\n",
    "    prod_crawler(prod_urls, cate_value)\n",
    "\n",
    "    \"\"\"\n",
    "    #累加1\n",
    "    for prod_url in prod_urls:\n",
    "        prod_dict[prod_url] = cate_value\n",
    "        print(prod_dict)\n",
    "        \n",
    "    #累加2\n",
    "    cate_prod_dict[cate_value] = prod_urls\n",
    "    print(cate_prod_dict.keys())\n",
    "    \n",
    "    \"\"\"    \n",
    "\n",
    "def prod_crawler(prod_urls, cate_value):\n",
    "    \n",
    "    content_list = []\n",
    "    for prod_url in prod_urls:\n",
    "\n",
    "        resp = requests.get(prod_url)\n",
    "        soup = BeautifulSoup(resp.text, 'html5lib')\n",
    "\n",
    "        prod_dict = {}\n",
    "\n",
    "        prod_dict['ID']       = 'gt' + soup.select('small')[1].text.replace(\"品號：\",\"\").replace(\".\",\"\").zfill(6)\n",
    "        prod_dict['category'] = cate_value\n",
    "        prod_dict['href']     = prod_url\n",
    "        prod_dict['name']     = soup.select('.pricetitle')[0].text\n",
    "        prod_dict['price']    = soup.select('.s_price')[0].text.replace(\",\",\"\").split()[1]\n",
    "        prod_dict['brand']    = [soup.select('small')[0].text + \"。\" + soup.select('div.writing > p')[1].text]\n",
    "        prod_dict['desc']     = [soup.select('p')[0].text + soup.select('div.writing > p')[0].text]\n",
    "        prod_dict['memo']     = soup.select('p')[1].text\n",
    "                \n",
    "        try:\n",
    "            url = \"https://www.giftu.com.tw/ws_prod.asmx/ShowReply\"\n",
    "            resps = requests.get(url)\n",
    "            comment_list = re.findall('\"ds-text\"&gt;(.+?)&', resps.text.replace(\"\\n\",\"\"))\n",
    "        except:\n",
    "            print(\"first error\")\n",
    "\n",
    "        try:\n",
    "            button_url = 'https://www.giftu.com.tw/' + re.findall('\"khs-btn\" href=\"(.*)\"&', resps.text)[0]\n",
    "            response = requests.get(button_url)\n",
    "            s = BeautifulSoup(response.text, 'html5lib')\n",
    "\n",
    "            name = s.select('.ds-name')\n",
    "            for i in range(len(name)):\n",
    "\n",
    "                text_list = s.select('.ds-text')[i].text.replace(\"\\r\",\"\")\n",
    "                comment_list.append(text_list)     \n",
    "        except:\n",
    "            print(\"second error\")\n",
    "\n",
    "        prod_dict['comment'] = comment_list\n",
    "        \n",
    "        \n",
    "        #picture\n",
    "        \n",
    "        p_list = [\"https://www.giftu.com.tw\" + soup.select('#Main_imgProduct')[0]['src']]\n",
    "        i=0\n",
    "        while True:\n",
    "            try:\n",
    "                soup.select('.imgfancybox > img')[i]['src']\n",
    "                p_list.append(soup.select('.imgfancybox > img')[i]['src'])\n",
    "                i+=1\n",
    "            except IndexError:\n",
    "                break\n",
    "        prod_dict['picture']    = p_list \n",
    "        \n",
    "        content_list.append(prod_dict)\n",
    "        \n",
    "    with open('gt_prod_%s_%s.json'%(cate_value, today), 'w') as f:\n",
    "        f.write(json.dumps(content_list, ensure_ascii=False, indent=4))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cate_dict = {1:'餐具廚具',2:'傢俱飾品',11:'書寫工具',12:'辦公用品',13:'個人配件',24:'首飾',15:'玩偶',16:'卡通經典'}\n",
    "    for cate_key in cate_dict.keys():\n",
    "        cate_value = cate_dict[cate_key]\n",
    "        cate_crawler(cate_key, cate_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
